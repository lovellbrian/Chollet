{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOv0ptns44cgfNpWfidRZmU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovellbrian/Chollet/blob/main/MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlVQg6lTnEB0"
      },
      "source": [
        "Chollet, P120\n",
        "\n",
        "#Introduction to Convnets\n",
        "We’re about to dive into the theory of what convnets are and why they have been so\n",
        "successful at computer vision tasks. But first, let’s take a practical look at a simple convnet\n",
        "example. It uses a convnet to classify MNIST digits, a task we performed in chapter\n",
        "2 using a densely connected network (our test accuracy then was 97.8%). Even though\n",
        "the convnet will be basic, its accuracy will blow out of the water that of the densely\n",
        "connected model from chapter 2.\n",
        "The following lines of code show you what a basic convnet looks like. It’s a stack of\n",
        "Conv2D and MaxPooling2D layers. You’ll see in a minute exactly what they do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db-PhdxmnL-J"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss9jl41tnPMS"
      },
      "source": [
        "Importantly, a convnet takes as input tensors of shape (image_height, image_width,\n",
        "image_channels) (not including the batch dimension). In this case, we’ll configure\n",
        "the convnet to process inputs of size (28, 28, 1), which is the format of MNIST\n",
        "images. We’ll do this by passing the argument input_shape=(28, 28, 1) to the first\n",
        "layer.\n",
        "Let’s display the architecture of the convnet so far:\n",
        ">>>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXTO-bxcnUAK",
        "outputId": "b69cfd2f-cec0-4fe8-9ce7-98b9eacae2f5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjL7U4jnnXo7"
      },
      "source": [
        "You can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of\n",
        "shape (height, width, channels). The width and height dimensions tend to shrink\n",
        "Listing 5.1 Instantiating a small convnet\n",
        "as you go deeper in the network. The number of channels is controlled by the first\n",
        "argument passed to the Conv2D layers (32 or 64).\n",
        "The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely\n",
        "connected classifier network like those you’re already familiar with: a stack of Dense\n",
        "layers. These classifiers process vectors, which are 1D, whereas the current output is a\n",
        "3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense layers\n",
        "on top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGZXp_o8nwIV"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTHKmy3Jn292"
      },
      "source": [
        "We’ll do 10-way classification, using a final layer with 10 outputs and a softmax activation.\n",
        "Here’s what the network looks like now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjheZPqKn-qm",
        "outputId": "54188d98-b47e-48f9-b4af-01c26751bd96"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TTz0UByoJui"
      },
      "source": [
        "As you can see, the (3, 3, 64) outputs are flattened into vectors of shape (576,)\n",
        "before going through two Dense layers.\n",
        "Now, let’s train the convnet on the MNIST digits. We’ll reuse a lot of the code from\n",
        "the MNIST example in chapter 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG8ZIocXoPV3",
        "outputId": "6dafb37d-1710-4342-a6c0-998d39e912bc"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 47s 4ms/step - loss: 0.3943 - accuracy: 0.8748\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0488 - accuracy: 0.9852\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0311 - accuracy: 0.9902\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0230 - accuracy: 0.9931\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0202 - accuracy: 0.9940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f33f01706d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX0N-4f-pupB"
      },
      "source": [
        "Let’s evaluate the model on the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjWW6R6Xpvyn",
        "outputId": "748844d5-e9b4-4cc6-9821-f3f4dde1d238"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0261 - accuracy: 0.9925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9925000071525574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IspnR5R2of1R"
      },
      "source": [
        "Whereas the densely connected network from chapter 2 had a test accuracy of 97.8%,\n",
        "the basic convnet has a test accuracy of 99.3%: we decreased the error rate by 68%\n",
        "(relative). Not bad!\n",
        "But why does this simple convnet work so well, compared to a densely connected\n",
        "model? To answer this, let’s dive into what the Conv2D and MaxPooling2D layers do."
      ]
    }
  ]
}